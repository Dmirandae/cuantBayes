# Markov Chain Monte Carlo (MCMC) Methods

## Introduction to MCMC Methods

- MCMC methods are statistical algorithms for sampling from probability distributions.
- They create a Markov chain with the desired distribution as its equilibrium state.
- Samples are generated by recording states from the chain.
- Accuracy improves with more steps.
- Various algorithms, including Metropolis–Hastings, are used in constructing these chains.

## MCMC for Generating Samples

- MCMC methods generate samples from a continuous random variable.
- Samples are proportional to a known function's probability density.
- Used for evaluating integrals over the variable, e.g., expected value or variance.

## Ensembles of Chains

- Ensembles of chains are developed by initiating stochastic processes or "walkers" from distant points.
- Walkers move randomly based on an algorithm prioritizing areas with higher contributions to the integral.
- Higher probabilities are assigned to these areas.

## Curse of Dimensionality

- Despite their effectiveness in multi-dimensional problems, MCMC methods face the curse of dimensionality.
- High-dimensional spaces cause regions of higher probability to stretch and get lost in vast spaces with little contribution to the integral.
- Methods like reducing walker step size can be employed, but it leads to high autocorrelation and increased computational expense.

## Advanced Methods

- To overcome challenges, advanced methods like Hamiltonian Monte Carlo and the Wang and Landau algorithm have been developed.
- These methods use techniques to reduce autocorrelation while keeping the process in integral-contributing regions.
- Although they rely on intricate theories and are harder to implement, they often converge faster than simpler approaches.

# Methods in Random Walk Monte Carlo

## Metropolis–Hastings Algorithm

- Generates a Markov chain using a proposal density for new steps.
- Includes a mechanism for rejecting certain proposed moves.
- Serves as a general framework, encompassing the original Metropolis algorithm and subsequent alternatives.

## Gibbs Sampling

- Designed for multi-dimensional target distributions.
- Updates each coordinate based on its full conditional distribution given other coordinates.
- Special case of Metropolis–Hastings with a uniform acceptance rate of 1; does not require tuning.
- Commonly used, structure resembles coordinate ascent variational inference.

## Metropolis-Adjusted Langevin Algorithm (MALA) and Gradient-Based Methods

- MALA and similar methods use the gradient (and possibly second derivative) of the log target density.
- Propose steps likely to move in the direction of higher probability density.

## Pseudo-Marginal Metropolis–Hastings

- Replaces direct evaluation of the target distribution density with an unbiased estimate.
- Useful when the target density is not analytically available (e.g., in latent variable models).

## Slice Sampling

- Involves sampling from a distribution by alternating between uniform sampling in the vertical direction and uniform sampling from the horizontal 'slice.'
- Based on the principle of sampling uniformly from the region under the plot of the density function.
