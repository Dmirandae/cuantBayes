
\documentclass{beamer}

\begin{document}

\title{Likelihood}
\subtitle{Hobbs 2015}
\author{DRME}
\date{\today}

\begin{frame}
  \titlepage
\end{frame}

\begin{frame}{Probability in Biology: Hobbs 4.1}
  \begin{itemize}
    \item Example: Tadpole observation in a pond.
  \end{itemize}
\end{frame}

\begin{frame}{Example: Tadpole Observation}
  \textbf{Scenario:}
  \begin{itemize}
    \item Collecting data on the number of tadpoles per volume of water in a pond.
    \item Observed 14 tadpoles in a 1 L sample.
    \item {\bf{TRUE}} average number of tadpoles per liter of water in the pond is 23.
  \end{itemize}

  \textbf{First Observation:}
  \begin{itemize}
  \item It is Poisson
    \item Probability of observing 14 tadpoles: $P(y_1 = 14|\lambda = 23) = \text{Poisson}(y_1 = 14|\lambda = 23) = 0.0136$.
  \end{itemize}

  \textbf{Second Observation:}
  \begin{itemize}
    \item Probability of observing 34 tadpoles: $P(y_2 = 34|\lambda = 23) = \text{Poisson}(y_2 = 34|\lambda = 23) = 0.0069$.
  \end{itemize}

  \textbf{Joint Probability:}
  \begin{itemize}
    \item Assuming independence: Joint probability = $0.0136 \times 0.0069 = 9.38 \times 10^{-5}$.
  \end{itemize}
\end{frame}

\begin{frame}{Independence of Observations}
  \begin{itemize}
    \item Independence assumption: Knowledge of one observation tells us nothing about the other.
    \item Joint probability calculation extended to any number of independent observations.
  \end{itemize}
\end{frame}

\begin{frame}{Remarks}
  \begin{itemize}
    \item Probability calculations provide insights into the likelihood of observations given a fixed average.
    \item Independence assumption crucial for joint probability calculations.
    \item The Poisson distribution to model catching probabilities.
  \end{itemize}
\end{frame}

\begin{frame}{Probability in Biology: Hobbs 4.2}
  \begin{itemize}
    \item Investigating decomposition of leaf litter over time.
    \item Using a simple model of exponential decay: \(\mu_t = e^{-kt}\).
    \item Data: \(y_t\) - observed proportions, {\bf{modeled with a beta distribution}}.
    \item Parameters: \(k\) (decay rate) and \(\sigma^2\) (variance).
  \end{itemize}
\end{frame}

\begin{frame}{Beta Distribution for \(y_t\)}
  \begin{itemize}
    \item Model the probability density of \(y_t\) with a beta distribution:
    \[ y_t | \mu_t, \sigma^2 \sim \text{beta}(\alpha_t, \beta_t) \]
    \item Moment matching for \(\alpha_t\) and \(\beta_t\):
    \begin{align*}
      \alpha_t &= \mu_t^2 - \mu_t^3 - \mu_t \sigma^2 \\
      \beta_t &= \mu_t - 2\mu_t^2 + \mu_t^3 - \sigma^2 + \mu_t \sigma^2
    \end{align*}
  \end{itemize}
\end{frame}

\begin{frame}{Conditional on Decay Rate \(k\) and \(\sigma^2\)}
  \begin{itemize}
    \item Conditional on known, fixed decay rate \(k = 0.01 \, \text{day}^{-1}\) and known, fixed \(\sigma^2 = 6 \times 10^{-4}\):
    \item Calculate parameters for the beta distribution on day 30:
    \begin{align*}
      \alpha_{30} &= 236.33 \\
      \beta_{30} &= 82.68
    \end{align*}
  \end{itemize}
\end{frame}

\begin{frame}{Probability Density Calculation}
  \begin{itemize}
    \item Given \(y_{30} = 0.7\), calculate the probability density:
    \[ f(y_{30} = 0.7) = 4.040 \]
    \item Interpretation: The probability that 70\% of the mass remains at time \(t = 30\) is 4.040.
  \end{itemize}
\end{frame}

\begin{frame}{Remarks}
  \begin{itemize}
    \item The beta distribution to model decay over time.
    \item Moment matching provides a method for estimating distribution parameters.
  \end{itemize}
\end{frame}


\begin{frame}{Introduction to Likelihood}
  \begin{itemize}
    \item Likelihood  measures the support provided by the observed data for different values of the parameter in a statistical model.
    \item The likelihood function is the foundation of maximum likelihood estimation (MLE).
  \end{itemize}
\end{frame}

\begin{frame}{Likelihood Function}
  \begin{itemize}
    \item The likelihood function, denoted as \(L(\theta; \mathbf{x})\), represents the probability of observing the given data \(\mathbf{x}\) for various parameter values \(\theta\) in the model.
    \item The likelihood function is not a probability distribution but provides a basis for estimating parameters.
  \end{itemize}
\end{frame}

\begin{frame}{Likelihood Example: Coin Toss}
  \begin{itemize}
    \item Consider a simple example: coin toss.
    \item Let \(\theta\) be the probability of getting heads (\(\theta \in [0, 1]\)).
    \item If we observe \(k\) heads in \(n\) tosses, the likelihood function is given by the binomial distribution:
    \[ L(\theta; k, n) = \binom{n}{k} \theta^k (1 - \theta)^{n-k} \]
  \end{itemize}
\end{frame}

\begin{frame}{Interpretation of Likelihood}
  \begin{itemize}
    \item Likelihood is not a probability, but it measures the compatibility of the observed data with different parameter values.
    \item Larger likelihood values indicate a better fit of the model to the observed data.
    \item The goal is to find the parameter values that maximize the likelihood, known as maximum likelihood estimation (MLE).
  \end{itemize}
\end{frame}

\begin{frame}{Likelihood in MLE}
  \begin{itemize}
    \item Maximum Likelihood Estimation (MLE) aims to find the parameter values that maximize the likelihood function.
    \item MLE is a common method for estimating parameters in statistical models.
    \item It provides point estimates that make the observed data most probable under the assumed model.
  \end{itemize}
\end{frame}

\begin{frame}{Likelihood Example: Population Growth}
  \begin{itemize}
    \item Consider a simple population growth model: \(N_t = N_0 \cdot e^{rt}\), where \(N_t\) is the population size at time \(t\), \(N_0\) is the initial population size, \(r\) is the growth rate, and \(e\) is the base of the natural logarithm.
    \item Likelihood function: \(L(r | \mathbf{y})\), where \(\mathbf{y}\) is the observed population size over time.
  \end{itemize}
\end{frame}

\begin{frame}{Likelihood Example: Phylogenetic Trees}
  \begin{itemize}
    \item In evolutionary biology, likelihood is extensively used in phylogenetic analysis.
    \item Given a phylogenetic tree and DNA sequence data, the likelihood of observing the given sequences under different substitution models is calculated.
    \item MLE finds the tree and model parameters that maximize the probability of the observed data.
  \end{itemize}
\end{frame}


\section{Probability Distribution vs. Likelihood Function}
 
 \input{like001.tex}
 
 
 
\section{Maximum Likelihood Estimation}

 \input{ML.tex}

 
\end{document}

